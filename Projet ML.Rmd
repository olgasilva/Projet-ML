---
title: "PROJET MACHINE LEARNING"
author: "Marlene CHEVALIER et Olga SILVA"
date: "Juin 2020"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r,warning=FALSE, message=FALSE}
library(caret)
library(tidyverse)
library(mice)
library("RColorBrewer")
library(VIM)
library("GGally") 
library("ggmap")
require(maps)
library(MASS)

```


# 1- Cadrage

L’objectif du projet est de mettre en oeuvre des méthodes d’apprentissage statistique dans un
cadre essentiellement prédictif

Le projet porte sur l’analyse de deux fichiers de données concernant une campagne marketing conduite auprès d’un ensemble de clients. Chaque ligne d’un fichier décrit un client. Le fichier projet-app-13-learn.csv contient en outre les résultats de la campagne pour les clients concernées. Les variables sont les suivantes :

* **age** : âge ;
* **sex** : genre ;
* **f_name** : prénom ;
* **last name** : nom;
* **commune** : nom de la commune de résidence ;
* **insee code** : code insee de la commune de résidence ;
* **city type** : type de la commune de résidence ;
* **department** : numéro du département de résidence ;
* **reg** : code de la région de résidence ;
* **catégorie** : code de catégorie socio-professionnelle, selon la table 1 ;
* **revenue** : salaire mensuel en équivalent temps plein (attention, cette information n’est pas disponible pour tous les clients) ;
* **cible** : résultat de la campagne codé par success pour un résultat considéré comme positif et failure dans le cas contraire.

Il est important de noter que Lyon, Paris et Marseille sont découpées en arrondissements et que le nom de commune est alors celui de la ville suivi de l’indication d’arrondissement.

Certaines variables seront naturellement lues comme des variables numériques (par exemple reg et catégorie) alors qu’elles ne contiennent pas des nombres mais des codes. Il est vivement conseillé de convertir les variables concernées au format factor en R pour faciliter la suite des traitements.

Il est aussi vivement conseillé d’enrichir les données fournies par des données annexes, notamment liées à la géographie de la France. 

# Contenu du Rapport (Index à construire)

1. Analyse exploratoire minimale des données (statistiques univariées, dépendances, etc.) ;
2. Justification du modèles prédictif choisi ;
3. Description précise de la chaîne de traitement : prétraitements éventuels, ajustement des modèles, choix du modèle, évaluation de ses performances attendues (le rapport doit impérativement contenir un tableau indiquant la qualité numérique attendue pour les prévisions sur le fichier test) ;
4. Analyse de l’importance des variables : cela peut être fait avant l’ajustement des modèles, pendant celui-ci ou après le choix du modèle final. Dans tous les cas, le rapport doit discuter de l’opportunité de construire des modèles sur une partie seulement des variables. Si c’est le cas, les prévisions finales et les performances attendues doivent concerner les modèles n’utilisant que les variables pertinentes ;
5. interprétation du modèle retenu : si cela est possible, une interprétation de la façon dont les décisions du modèle retenu sont prises fournira un complément très important au reste de l’analyse.

# 1.Preparation des données

## 1.1 - Charger les données. 

Voici la structure du dataset d'entraînement. Nous avons 10 000 observations et 12 variables 

```{r}
learn = read.csv("projet-app-13-learn.csv",header = TRUE,encoding = "UTF-8")
test = read.csv("projet-app-13-test.csv",header = TRUE,encoding = "UTF-8")
glimpse(learn)
```

## 1.2- Changement du format: 

Nous allons renommer la variable catégorie, pour enlever l'accent et convertir celle-ci et la région au format nominal. Il vont nous rester uniquement deux variables en format numérique, l'âge et le revenue

```{r}
learn <- learn %>% rename(categorie = catégorie)
test <- test %>% rename(categorie = catégorie)

learn$reg = as.factor(learn$reg)
learn$categorie = as.factor(learn$categorie)

test$reg = as.factor(test$reg)
test$categorie = as.factor(test$categorie)
```

## 1.3- Completer avec les données géographiques

```{r}
cities_gps = read.csv("cities-gps.csv",header = TRUE,encoding = "UTF-8")
cities_population = read.csv("cities-population.csv",header = TRUE,encoding = "UTF-8")
dept = read.csv("departments.csv",header = TRUE,encoding = "UTF-8")
regions = read.csv("regions.csv",header = TRUE,encoding = "UTF-8")
```

Ajoutons les coordonnées géographiques et la population. Nous n'avons pas besoin d'ajouter le nom du département pour l'instant.

```{r}
learn=merge(x=learn,y=cities_gps,by.x = "insee.code",by.y="id")
learn=merge(x=learn,y=cities_population,by.x = "insee.code",by.y="id")
learn=merge(x=learn,y=regions,by.x = "reg",by.y="id")

test=merge(x=test,y=cities_gps,by.x = "insee.code",by.y="id")
test=merge(x=test,y=cities_population,by.x = "insee.code",by.y="id")
test=merge(x=test,y=regions,by.x = "reg",by.y="id")

learn <- learn %>% rename(REGION = name)
test <- test %>% rename(REGION = name)
```

## 1.4- Traitement des données manquantes 

La variable revenue a 5320 valeurs manquantes  pour le dataset de learn (53%) et 5175 pour le dataset de test (51%)

```{r}
colSums(is.na(learn))
colSums(is.na(test))
```

**A garder ces graphiques? En annexe?** 
Voici deux visualisations des données manquantes, qui nous confirmemt qu'uniquement la variable revenus a des valeurs manquantes et ils sont repartis tout au long du dataset

```{r, fig.height = 3, fig.width = 4}
respattern=md.pattern(learn,rotate.names = TRUE)
```

```{r, fig.height = 3.5, fig.width = 5}
matrixplot(learn)
```

**Pourquoi il y a des valeurs manquantes?**

Avant de traiter ce problème, regardons pourquoi et quand les données sont manquantes. Nous allons uniquement nous concentrer sur la variable revenue. 

```{r,fig.height = 3.5, fig.width = 5,warning=FALSE}
ggplot(learn, aes(revenue))+geom_histogram(fill="firebrick",bins=40)
```

Afin d'avoir plus d'information sur les données manquantes, nous allons utiliser le graphique "Marginplot". Observons les revenus vs l'âge. 

```{r,fig.height = 4, fig.width = 6}
marginplot(learn[,c("revenue","age")])
```

Dans ce graphique, les points sans valeurs manquants apparaissent dans le scatterplot. On observe qu'il manque des valeurs dans toutes les âges (ligne rouge verticale, de 15 à 100 ans). En plus nous avons les boxplots des distributions des valeurs, en rouge quand la valeur est manquante et en bleu quand la valeur est observée. 

Les valeurs des revenues sont observées uniquement dans les tranches d'âge entre 18 ans et 69 ans, la période qui pourrait être considérée comme active au niveau professionnel. 

Si on observe par rapport à la catégorie :

```{r,fig.height = 4, fig.width = 6}
marginplot(learn[,c("revenue","categorie")])
```

Selon le graphique, il y a que trois catégories sans revenues (10, 11 et 12), effectivement des personnes sans revenues : Chômeurs, Inactifs et Retraités. Les revenues le plus élevés se trouvent dans la catégorie cadres. Sur le reste des catégories, nous ne trouverons pas des données absentes.

En ce qui concerne le genre, nous avons des données absentes pour les deux catégories, cependant les hommes ont les salaires le plus élevés de l'échantillon.

```{r,fig.height = 4, fig.width = 6}
marginplot(learn[,c("revenue","sex")])
```

Pour la région aussi, il semblerait aussi que nous avons des données manquantes pour toutes les régions :

```{r,fig.height = 4, fig.width = 6}
marginplot(learn[,c("revenue","reg")])
```
Pour la cible, on observe qu'il y a des données manquantes pour les deux catégories : Failure et success. Mais leur absence n'est pas equilibrée, on retrouve plus des données absentes pour l'échec que pour le succès.

```{r,fig.height = 4, fig.width = 6}
marginplot(learn[,c("revenue","cible")])
nrow(subset(learn, is.na(revenue) & cible =="failure"))
nrow(subset(learn, is.na(revenue) & cible =="success"))
```
`

# 2 - Analyse exploratoire des données

Les données semblent bien equilibrées entre les deux catégories à predire : Failure et Success

```{r,fig.height = 3.5, fig.width = 5}
ggplot(learn, aes(cible))+geom_bar(fill="firebrick")
```

Nous observons une distribution très différente selon l'âge : l'échec est bien répartie entre 25 et 75 ans, par contre le succès est concentré entre 30 et 55 ans, avec quelques valeurs extrêmes superieurs à 75 ans. L'âge est sûrement une variable qui sera pertinente pour la prediction.

Pour la population et les revenues, il ne semble pas avoir des différences. 

```{r,fig.height = 3, fig.width = 4, warning=FALSE}
par(mfrow=c(2,2))
ggplot(learn, aes(cible,age))+geom_boxplot(fill="deepskyblue")
ggplot(learn, aes(cible,population))+geom_boxplot(fill="darkorange")
ggplot(learn, aes(cible,revenue))+geom_boxplot(fill="darkorchid")

```

Les hommes ont un taux d'échec (60%) plus élevé que les femmes (45%). Pour les âges, la medianne de l'échec des femmes est autour de 70 ans et pour les hommes 50 ans. 

L'échantillon est composé d’un plus grand nombre de femmes que d’hommes (5259 vs 4741)


```{r,fig.height = 3.5, fig.width = 5}
ggplot(learn, aes(x = cible, y = age, fill = sex)) + geom_boxplot()+scale_fill_brewer(palette="Set2")
table(learn$sex, learn$cible)
```

La region Ile de France cumule une bonne partie des resultats, mais en global ils semblent bien equilibrés. Le succes se concentrent dans l'Ile de France

La région Corse a une participation très basse

```{r,fig.height = 4.5, fig.width = 6}
ggplot(learn, aes(REGION)) + geom_bar(aes(fill=cible),position = "dodge") + scale_fill_brewer(palette="Set1")+theme(axis.text.x = element_text(angle = 90))
table(learn$REGION, learn$cible)
```

Les retraités et les étudiants (catégorie 13 et 10), enregistrent la plupart des échecs, tandis que les catégories 2 a 8, 11 et 12 (chomeurs et inactifs) ont la plupart des succès, surement il s'agit d'une des variables à garder pour la prédiction.

```{r,fig.height = 3.5, fig.width = 5}
ggplot(learn, aes(categorie))+geom_bar(aes(fill=cible))+scale_fill_brewer(palette="PiYG")
table(learn$categorie, learn$cible)
```

Paris, en tant que capitale, enregistre très peu de résultats, en sachant que la région Ile de France c'est la plus représentée dans l'échantillon. 

Les âges sont bien reparties entre toutes les types de communes. 

```{r,fig.height = 3.5, fig.width = 5}
ggplot(learn, aes(city.type))+geom_bar(aes(fill=cible),position = "dodge") + scale_fill_brewer(palette="Accent")+theme(axis.text.x = element_text(angle = 90))
table(learn$city.type, learn$cible)
ggplot(learn, aes(x = city.type, y = age)) + geom_boxplot(aes(fill=cible))+theme(axis.text.x = element_text(angle = 90))
```


Voici la repartition des reponses sur toute la france, on observe plus de succèss au nord et plus des echecs au sud (region Auvergne-Rhône-Alpes):

```{r}
mapa_mundo <- map_data("world", region = "France")

mapa_mundo %>%
  ggplot() +
  geom_polygon(aes( x= long, y = lat, group = group),
               fill = "grey80",
               color = "white") +
  geom_point(data= learn, 
             aes(x=longitude, y = latitude, color = cible))+
  scale_color_manual(values = c( "darkorange", "purple"), name = " ") + 
  ggtitle( "Carte")
```

Ce graphique montre que les variables qui vont beaucoup influencer notre prediction seront surement l'age

```{r, warning=FALSE,message=FALSE}
learn2 <-select(learn,-c(insee.code,f_name,last.name,commune, department, latitude, longitude,X,Y,REGION,city.type,reg))
ggpairs(learn2,aes(color="blue")) 
```


# 3 - Ajustement des modèles

## 3.1 - Régression logistique**

**Validation croisée**

```{r}
set.seed(123) ## pour pouvoir le reproduire

learn3 = subset(learn, select=-c(insee.code,f_name,last.name,commune, department, latitude, longitude,X,Y,reg,revenue))

trainIndex = createDataPartition(learn3$cible,p=0.7, list=FALSE,times=1)
 
train = learn3[trainIndex,]
valid = learn3[-trainIndex,]
```

```{r}
 

model1<-glm(cible~., data=train,family = binomial(logit))
model2<-glm(cible ~ 1, data=train,family = binomial(logit))
model2.step <- stepAIC(model2, direction = "both", scope=list(upper=model1,lower=model2),trace = FALSE)
summary(model2.step)

```

**Prediction**

```{r }
glm.pred1 <- predict(model2.step, newdata = valid, type = "response")
table(glm.pred1 > 0.5, valid$cible)


```



**Solution - Imputation des données**

Pour que l'imputation fonctionne, il faut enlever des colonnes avec trop de catégories, et celles qui ne devraient pas apporter plus d'information comme le prénom et le nom.

L'imputation avec mice, sera faite avec rf : "Random forest imputation", en utilisant les données d'age, sex, region, categorie et population pour trouver le revenue correspondant. 

```{r}
#learn2<-select(learn,-c(insee.code,f_name,last.name,commune, department, latitude, longitude,X,Y))
#impforest = mice(learn2, method = "rf", m = 30, seed = 600, print=FALSE)
#learn_complete=complete(impforest)
#learn_complete<-cbind(learn_complete,select(learn,c(insee.code,f_name,last.name,commune, department, #latitude, longitude,X,Y)))
```

```{r}
#test2<-select(test,-c(insee.code,f_name,last.name,commune, department, latitude, longitude,X,Y))
#impforest2 = mice(test2, method = "rf", m = 30, seed = 600, print=FALSE)
#test_complete=complete(impforest2)
#test_complete<-cbind(test_complete,select(test,c(insee.code,f_name,last.name,commune, department, latitude, #longitude,X,Y)))
```

Nous verifions que l'imputation respecte bien la structure des données orginal, et c'est bien le cas :

```{r}
#par(mfrow=c(1,2))
#densityplot(impforest, main="Forêts aléatoires sur train", layout = c(2, 3))
#densityplot(impforest2, main="Forêts aléatoires sur test", layout = c(2, 3))
```


# 2 Modèles prédictives (à suivre)


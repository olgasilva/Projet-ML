---
title: "PROJET MACHINE LEARNING"
author: "Marlene CHEVALIER et Olga SILVA"
date: "3/12/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r,warning=FALSE, message=FALSE}
library(caret)
library(tidyverse)
library(mice)
library("RColorBrewer")
library(VIM)

library("ggmap")
require(maps)

```


# 1- Cadrage

L’objectif du projet est de mettre en oeuvre des méthodes d’apprentissage statistique dans un
cadre essentiellement prédictif

Le projet porte sur l’analyse de deux fichiers de données concernant une campagne marketing conduite auprès d’un ensemble de clients. Chaque ligne d’un fichier décrit un client. Le fichier projet-app-13-learn.csv contient en outre les résultats de la campagne pour les clients concernées. Les variables sont les suivantes :
— **age** : âge ;
— **sex** : genre ;
— **f_name** : prénom ;
— **last name** : nom;
— **commune** : nom de la commune de résidence ;
— **insee code** : code insee de la commune de résidence ;
— **city type** : type de la commune de résidence ;
— **department** : numéro du département de résidence ;
— **reg** : code de la région de résidence ;
— **catégorie** : code de catégorie socio-professionnelle, selon la table 1 ;
— **revenue** : salaire mensuel en équivalent temps plein (attention, cette information n’est pas disponible pour tous les clients) ;
— **cible** : résultat de la campagne codé par success pour un résultat considéré comme positif et failure dans le cas contraire.

Il est important de noter que Lyon, Paris et Marseille sont découpées en arrondissements et que le nom de commune est alors celui de la ville suivi de l’indication d’arrondissement.

Certaines variables seront naturellement lues comme des variables numériques (par exemple reg et catégorie) alors qu’elles ne contiennent pas des nombres mais des codes. Il est vivement conseillé de convertir les variables concernées au format factor en R pour faciliter la suite des traitements.

Il est aussi vivement conseillé d’enrichir les données fournies par des données annexes, notamment liées à la géographie de la France. 

# Contenu du Rapport (CELA VA ETRE NOTRE INDEX PLUS TARD)

1. Analyse exploratoire minimale des données (statistiques univariées, dépendances, etc.) ;
2. Justification du modèles prédictif choisi ;
3. Description précise de la chaîne de traitement : prétraitements éventuels, ajustement des modèles, choix du modèle, évaluation de ses performances attendues (le rapport doit impérativement contenir un tableau indiquant la qualité numérique attendue pour les prévisions sur le fichier test) ;
4. Analyse de l’importance des variables : cela peut être fait avant l’ajustement des modèles, pendant celui-ci ou après le choix du modèle final. Dans tous les cas, le rapport doit discuter de l’opportunité de construire des modèles sur une partie seulement des variables. Si c’est le cas, les prévisions finales et les performances attendues doivent concerner les modèles n’utilisant que les variables pertinentes ;
5. interprétation du modèle retenu : si cela est possible, une interprétation de la façon dont les décisions du modèle retenu sont prises fournira un complément très important au reste de l’analyse.

# 1.Preparation des données

## 1.1 - Charger les données. Voici la structure du dataset d'entraînement. Nous avons 10 000 observations et 12 variables 

```{r}
learn = read.csv("projet-app-13-learn.csv",header = TRUE,encoding = "UTF-8")
test = read.csv("projet-app-13-test.csv",header = TRUE,encoding = "UTF-8")
glimpse(learn)
```

## 1.2- Changement du format: nous allons renommer la variable catégorie, pour enlever l'accent et convertir celle-ci et la région au format nominal. Il vont nous rester uniquement deux variables en format numérique, l'âge et le revenue
```{r}
learn <- learn %>% rename(categorie = catégorie)
test <- test %>% rename(categorie = catégorie)

learn$reg = as.factor(learn$reg)
learn$categorie = as.factor(learn$categorie)

test$reg = as.factor(test$reg)
test$categorie = as.factor(test$categorie)
```

##1.3- Completer avec les données géographiques

```{r}
cities_gps = read.csv("cities-gps.csv",header = TRUE,encoding = "UTF-8")
cities_population = read.csv("cities-population.csv",header = TRUE,encoding = "UTF-8")
dept = read.csv("departments.csv",header = TRUE,encoding = "UTF-8")
regions = read.csv("regions.csv",header = TRUE,encoding = "UTF-8")
```

Ajoutons les coordonnées géographiques et la population. Nous n'avons pas besoin d'ajouter le nom du département ni de la région pour l'instant.

```{r}
learn=merge(x=learn,y=cities_gps,by.x = "insee.code",by.y="id")
learn=merge(x=learn,y=cities_population,by.x = "insee.code",by.y="id")

test=merge(x=test,y=cities_gps,by.x = "insee.code",by.y="id")
test=merge(x=test,y=cities_population,by.x = "insee.code",by.y="id")
```

## 1.4- Traitement des données manquantes 

La variable revenue a 5320 valeurs manquantes  pour le dataset de learn (53%) et 5175 pour le dataset de test (51%)

```{r}
colSums(is.na(learn))
colSums(is.na(test))
```

**A garder ces graphiques? En annexe?** 
Voici deux visualisations des données manquantes, qui nous confirmemt qu'uniquement la variable revenus a des valeurs manquantes et ils sont repartis tout au long du dataset

```{r, fig.height = 3.5, fig.width = 5}
respattern=md.pattern(learn,rotate.names = TRUE)
matrixplot(learn)
```

Pour que l'imputation fonctionne, il faut enlever des colonnes avec trop de categories, et celles qui ne devraient pas apporter plus d'information comme le prénom et le nom.

L'imputation avec mice, sera faite avec rf : "Random forest imputation", en utilisant les données d'age, sex, region, categorie et population pour trouver le revenue correspondant. 

```{r}
learn2<-select(learn,-c(insee.code,f_name,last.name,commune, department, latitude, longitude,X,Y))
impforest = mice(learn2, method = "rf", m = 30, seed = 600, print=FALSE)
learn_complete=complete(impforest)
learn_complete<-cbind(learn_complete,select(learn,c(insee.code,f_name,last.name,commune, department, latitude, longitude,X,Y)))
```

```{r}
test2<-select(test,-c(insee.code,f_name,last.name,commune, department, latitude, longitude,X,Y))
impforest2 = mice(test2, method = "rf", m = 30, seed = 600, print=FALSE)
test_complete=complete(impforest2)
test_complete<-cbind(test_complete,select(test,c(insee.code,f_name,last.name,commune, department, latitude, longitude,X,Y)))
```

Nous verifions que l'imputation respecte bien la structure des données orginal, et c'est bien le cas :

```{r}
densityplot(impforest, main="Forêts aléatoires", layout = c(2, 3))
densityplot(impforest2, main="Forêts aléatoires", layout = c(2, 3))
```

# 2 - Analyse exploratoire des données

Les données semblent bien reparties entre les deux catégories à predire : Failure et Success

```{r}
ggplot(learn_complete, aes(cible))+geom_bar(fill="firebrick")
```

Nous observons une distribution très différente selon l'âge : l'échec est bien répartie entre 25 et 75 ans, par contre le succès est concentré entre 30 et 55 ans, avec quelques valeurs extrêmes superieurs à 75 ans. Une variable qui sera pertinente pour la prediction.

Pour la population et les revenues, il ne semble pas avoir des différences. 

```{r}
par(mfrow=c(2,2))
ggplot(learn_complete, aes(cible,age))+geom_boxplot(fill="deepskyblue")
ggplot(learn_complete, aes(cible,population))+geom_boxplot(fill="darkorange")
ggplot(learn_complete, aes(cible,revenue))+geom_boxplot(fill="darkorchid")
```

Les hommes ont un taux d'échec (60%) plus élevé que les femmes (45%). Pour les âges, la medianne de l'échec des femmes est autour de 70 ans et pour les hommes 50 ans. 

L'échantillon est composé d’un plus grand nombre de femmes que d’hommes (5259 vs 4741)


```{r}
ggplot(learn_complete, aes(x = cible, y = age, fill = sex)) + geom_boxplot()+scale_fill_brewer(palette="Set2")
table(learn_complete$sex, learn_complete$cible)
```

La region 11 (Ile de France) cumule une bonne partie des resultats, mais en global ils semblent bien equilibrés, sauf pour la region 76 (OCCITANIE), 84 (AUVERGNE RHONE ALPES) et 93 (PROVENCE ALPES COTE D'AZUR). 
La région 94 (Corse) a une participation très basse

```{r}
ggplot(learn_complete, aes(reg)) + geom_bar(aes(fill=cible),position = "dodge") + scale_fill_brewer(palette="Set1")
table(learn_complete$reg, learn_complete$cible)
```

Les retraités et les étudiants (catégorie 13 et 10), enregistrent la plupart des échecs, tandis que les catégories 2 a 8, 11 et 12 (chomeurs et inactifs) ont la plupart des succès, surement il s'agit d'une des variables à garder pour la prédiction.

```{r}
ggplot(learn_complete, aes(categorie))+geom_bar(aes(fill=cible))+scale_fill_brewer(palette="PiYG")
table(learn_complete$categorie, learn_complete$cible)
```

Paris, en tant que capitale, enregistre très peu de résultats, en sachant que la région Ile de France c'est la plus représentée dans l'échantillon. 

Les ages sont bien reparties entre toutes les types de communes. 

```{r}
ggplot(learn_complete, aes(city.type))+geom_bar(aes(fill=cible),position = "dodge") + scale_fill_brewer(palette="Accent")+theme(axis.text.x = element_text(angle = 90))
table(learn_complete$city.type, learn_complete$cible)
ggplot(learn_complete, aes(x = city.type, y = age)) + geom_boxplot(aes(fill=cible))+theme(axis.text.x = element_text(angle = 90))
```

Voici la repartition des reponses sur toute la france

```{r}
mapa_mundo <- map_data("world", region = "France")

mapa_mundo %>%
  ggplot() +
  geom_polygon(aes( x= long, y = lat, group = group),
               fill = "grey80",
               color = "white") +
  geom_point(data= learn_complete, 
             aes(x=longitude, y = latitude, color = cible))+
  scale_color_manual(values = c( "darkorange", "purple"), name = " ") + 
  ggtitle( "Carte")
```




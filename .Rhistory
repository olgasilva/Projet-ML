niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
sigma
d=read.csv("shuttle.txt",sep="\t")
View(d)
library("mcmc")
#EMV pour beta0 beta1 par le modele probit
modlog=glm(damage~tempF,data=d,family = binomial(link="probit"))
summodlog=summary(modlog)
sigma=summodlog$cov.unscaled
betaEMV=(summodlog$coefficients[,1])
# On peut par exemple prendre des priors N(0,10^2) indépendantes
prior = function(beta){
return(dnorm(beta[1], 0, 10) * dnorm(beta[2], 0, 10))
}
posterior = function(beta, y, x){
p = pnorm(beta[1] + x*beta[2])
lkd = prod(p^y) * prod((1-p)^(1-y))
return(lkd * prior(beta))
}
library(mvtnorm)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
proposal = rmvnorm(1, beta[i-1, ], tau^2*sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],tempF,damage)/posterior(beta[i, ],tempF,damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
class(tau)
posterior = function(beta, y, x){
p = pnorm(beta[1] + x*beta[2])
lkd = prod(p^y) * prod((1-p)^(1-y))
return(lkd * prior(beta))
}
library(mvtnorm)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
proposal = rmvnorm(1, beta[i-1, ], tau^2*sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],tempF,damage)/posterior(beta[i, ],tempF,damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
?rmvnorm
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
proposal = rmvnorm(1, beta[i-1, ], tau^2*det(sigma)) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],tempF,damage)/posterior(beta[i, ],tempF,damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
proposal = rmvnorm(1, beta[i-1, ], tau^2) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],tempF,damage)/posterior(beta[i, ],tempF,damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
proposal = rmvnorm(1, beta[i-1, ], sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],tempF,damage)/posterior(beta[i, ],tempF,damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
# proposal = rmvnorm(1, beta[i-1, ], tau^2*sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],tempF,damage)/posterior(beta[i, ],tempF,damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
# proposal = rmvnorm(1, beta[i-1, ], tau^2*sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],tempF,damage)/posterior(beta[i, ],tempF,damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
d=read.csv("shuttle.txt",sep="\t")
View(d)
library("mcmc")
#EMV pour beta0 beta1 par le modele probit
modlog=glm(damage~tempF,data=d,family = binomial(link="probit"))
summodlog=summary(modlog)
sigma=summodlog$cov.unscaled
betaEMV=(summodlog$coefficients[,1])
# On peut par exemple prendre des priors N(0,10^2) indépendantes
prior = function(beta){
return(dnorm(beta[1], 0, 10) * dnorm(beta[2], 0, 10))
}
# loi a posteriori
posterior = function(beta, y, x){
p = pnorm(beta[1] + x*beta[2])
lkd = prod(p^y) * prod((1-p)^(1-y))
return(lkd * prior(beta))
}
library(mvtnorm)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
# proposal = rmvnorm(1, beta[i-1, ], tau^2*sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],tempF,damage)/posterior(beta[i, ],tempF,damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
d=read.csv("shuttle.txt",sep="\t")
View(d)
library("mcmc")
#EMV pour beta0 beta1 par le modele probit
modlog=glm(damage~tempF,data=d,family = binomial(link="probit"))
summodlog=summary(modlog)
sigma=summodlog$cov.unscaled
betaEMV=(summodlog$coefficients[,1])
# On peut par exemple prendre des priors N(0,10^2) indépendantes
prior = function(beta){
return(dnorm(beta[1], 0, 10) * dnorm(beta[2], 0, 10))
}
# loi a posteriori
posterior = function(beta, y, x){
p = pnorm(beta[1] + x*beta[2])
lkd = prod(p^y) * prod((1-p)^(1-y))
return(lkd * prior(beta))
}
library(mvtnorm)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
# proposal = rmvnorm(1, beta[i-1, ], tau^2*sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],d$tempF,d$damage)/posterior(beta[i, ],d$tempF,d$damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
# Bayesien TD 3 Metropolis Hastings sur shuttle.txt
d=read.csv("shuttle.txt",sep="\t")
View(d)
attach(d)
library("mcmc")
#EMV pour beta0 beta1 par le modele probit
modlog=glm(damage~tempF,data=d,family = binomial(link="probit"))
summodlog=summary(modlog)
sigma=summodlog$cov.unscaled
betaEMV=(summodlog$coefficients[,1])
# On peut par exemple prendre des priors N(0,10^2) indépendantes
prior = function(beta){
return(dnorm(beta[1], 0, 10) * dnorm(beta[2], 0, 10))
}
# loi a posteriori
posterior = function(beta, y, x){
p = pnorm(beta[1] + x*beta[2])
lkd = prod(p^y) * prod((1-p)^(1-y))
return(lkd * prior(beta))
}
library(mvtnorm)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
# proposal = rmvnorm(1, beta[i-1, ], tau^2*sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],d$tempF,d$damage)/posterior(beta[i, ],d$tempF,d$damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
proposal = rmvnorm(1, beta[i-1, ], tau^2*sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = min(1,posterior(beta[i-1, ],d$tempF,d$damage)/posterior(beta[i, ],d$tempF,d$damage))# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
MH = function(beta0, niter, tau){
beta = matrix(NA, nrow=niter, ncol=2)
beta[1, ] = beta0
for(i in 2:niter){
proposal = rmvnorm(1, beta[i-1, ], tau^2*sigma) # genere un vecteur de variables aléatoires normale multivariées
alpha = 0.02# probabilité d'acceptation
if(runif(1) < alpha){
# on accepte
}
else{
# on rejette
}
}
return(beta)
}
niter = 2e3
b1 = MH(c(-3,0), niter, 1)
b2 = MH(c(2,0), niter, 1)
b3 = MH(c(2,-0.3), niter, 1)
b4 = MH(c(0, 0), niter, .1)
b5 = MH(c(0, -.01), niter, 1)
install.packages("randomForest")
install.packages("xgboost")
library(matrix)
install.packages("Matrix")
install.packages("zoo")
install.packages("latexpdf")
install.packages("latex2exp")
install.packages("mvtnorm")
?mvtnorm
install.packages("class")
install.packages("ROCR")
library(ROCR)
fr <- data.frame(score = c(0.61, 0.36, 0.43, 0.14, 0.38, 0.24, 0.97, 0.89, 0.78, 0.86, 0.71, 0.36),
label = c(1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0))
pred <- prediction(fr$score, fr$label)
pred
table(pred,fr$score)
library(ROCR)
fr <- data.frame(score = c(0.61, 0.36, 0.43, 0.14, 0.38, 0.24, 0.97, 0.89, 0.78, 0.86, 0.71, 0.36),
label = c(1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0))
pred <- prediction(fr$score, fr$label)
perf <- performance(pred, "tpr", "fpr")
plot(perf)
library(ROCR)
fr <- data.frame(score = c(0.61, 0.36, 0.43, 0.14, 0.38, 0.24, 0.97, 0.89, 0.78, 0.86, 0.71, 0.36),
label = c(1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0))
pred <- prediction(fr$score, fr$label)
perf <- performance(pred, "auc")
perf@y.values[[1]]
library(ROCR)
fr <- data.frame(score = c(0.61, 0.36, 0.43, 0.14, 0.38, 0.24, 0.97, 0.89, 0.78, 0.86, 0.71, 0.36),
label = c(1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0))
pred <- prediction(fr$score, fr$label)
perf <- performance(-pred, "tpr", "fpr")
plot(perf)
library(ROCR)
fr <- data.frame(score = c(0.61, 0.36, 0.43, 0.14, 0.38, 0.24, 0.97, 0.89, 0.78, 0.86, 0.71, 0.36),
label = c(1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0))
pred <- prediction(fr$score, fr$label)
perf <- performance(1/pred, "tpr", "fpr")
plot(perf)
# Courbe de ROC
library(ROCR)
fr <- data.frame(score = c(0.61, 0.36, 0.43, 0.14, 0.38, 0.24, 0.97, 0.89, 0.78, 0.86, 0.71, 0.36),
label = c(1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0))
pred <- prediction(fr$score, fr$label)
perf <- performance(pred, "tpr", "fpr")
plot(perf)
knitr::opts_chunk$set(echo = FALSE)
# Librairies
library(caret)
library(tidyverse)
library(gridExtra)
library(mice)
library("RColorBrewer")
library(VIM)
library("GGally")
library("ggmap")
require(maps)
library(MASS)
library(ROCR)
library(rpart)
library(rpart.plot)
library(InformationValue)
# Librairies
library(caret)
library(tidyverse)
library(gridExtra)
library(mice)
library("RColorBrewer")
library(VIM)
library("GGally")
library("ggmap")
require(maps)
library(MASS)
library(ROCR)
library(rpart)
library(rpart.plot)
library(InformationValue)
install.packages("sf")
install.packages("raster")
install.packages("spData")
install.packages("SpDATALarger")
install.packages("tmap")
install.packages("cowplot")
setwd("C:/Users/Marlène/Desktop/MachineLearning/Projet-ML")
setwd("C:/Users/Marlène/Desktop/MachineLearning/Projet-ML")
knitr::opts_chunk$set(echo = FALSE,message=FALSE, warning=FALSE)
# Packages untilisés
library(caret)
library(tidyverse)
library(gridExtra)
library(plotly)
library(mice)
library("RColorBrewer")
library(VIM)
library("GGally")
library("ggmap")
require(maps)
library(MASS)
library(ROCR)
library(rpart)
library(rpart.plot)
library(InformationValue)
# parametrage des graphiques
theme_set=(theme_bw()+theme(plot.title=element_text(hjust=0.5,size=14,face="bold"),plot.subtitle=element_text(hjust=0.5,size=12) ,axis.title=element_text(size=10)))
#chargement des jeux de données d'entrainement et test
learn = read.csv("projet-app-13-learn.csv",header = TRUE,encoding = "UTF-8")
test = read.csv("projet-app-13-test.csv",header = TRUE,encoding = "UTF-8")
# renommage de variable
learn=learn %>% rename(categorie = catégorie)
test=test %>% rename(categorie = catégorie)
#chargement des jeux de données d'entrainement et test
learn = read.csv("projet-app-13-learn.csv",header = TRUE,encoding = "UTF-8")
test = read.csv("projet-app-13-test.csv",header = TRUE,encoding = "UTF-8")
# chargement des données géographiques
cities_gps = read.csv("cities-gps.csv",header = TRUE,encoding = "UTF-8")
cities_population = read.csv("cities-population.csv",header = TRUE,encoding = "UTF-8")
dept = read.csv("departments.csv",header = TRUE,encoding = "UTF-8")
regions = read.csv("regions.csv",header = TRUE,encoding = "UTF-8")
# renommage de variable
learn=learn %>% rename(categorie = catégorie)
test=test %>% rename(categorie = catégorie)
#conversion variables en factor
learn$reg = as.factor(learn$reg)
learn$categorie = as.factor(learn$categorie)
test$reg = as.factor(test$reg)
test$categorie = as.factor(test$categorie)
# retraitement variable cible
learn$cible= as.character(learn$cible)
learn$cible[learn$cible == "failure"]=FALSE
learn$cible[learn$cible == "success"]=TRUE
learn$cible=as.logical(learn$cible)
test$cible= as.character(test$cible)
# effectif femmes
l.nrowF=sum(learn$sex=="Female")
l.txF=round((l.nrowF/nrow(learn)*100))
# effectif hommes
l.nrowM=sum(learn$sex=="Male")
l.txM=round((l.nrowM/nrow(learn)*100))
# taux de succès
l.nrowsucF=learn %>% group_by(sex)  %>% count(cible) %>%
filter(cible=="TRUE" & sex=="Female") %>% select(cible)
# effectif femmes
l.nrowF=sum(learn$sex=="Female")
l.txF=round((l.nrowF/nrow(learn)*100))
# effectif hommes
l.nrowM=sum(learn$sex=="Male")
l.txM=round((l.nrowM/nrow(learn)*100))
# taux de succès
l.nrowsucF=learn %>% group_by(sex)  %>% count(cible) %>%
filter(cible=="TRUE" & sex=="Female")
l.nrowsucF
p6=ggplot(learn, aes(x = sex, fill= cible)) +
labs(title = "Répartition du succès/échec",
x = "Sexe", y = "Nombre d'observations",
subtitle = "en fonction du sexe") +
scale_fill_manual(values=c("brown2","lightskyblue"),label=c("Echec","Succès"))+
geom_bar(col = "black")
p6
l.nrowF=sum(learn$sex=="Female")
l.txF=round((l.nrowF/nrow(learn)*100))
l.nrowM=sum(learn$sex=="Male")
l.txM=round((l.nrowM/nrow(learn)*100))
l.cibleT=sum(learn$cible=="TRUE")
l.cibleF=sum(learn$cible=="FALSE")
l.txcibleT=round((l.cibleF/nrow(learn)*100))
setwd("C:/Users/Marlène/Desktop/MachineLearning/Projet-ML")
